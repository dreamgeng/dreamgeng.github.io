<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>分析Ajax爬取今日头条街拍美图 | dreamgeng</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">分析Ajax爬取今日头条街拍美图</h1><a id="logo" href="/.">dreamgeng</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">分析Ajax爬取今日头条街拍美图</h1><div class="post-meta">Jan 23, 2019<span> | </span><span class="category"><a href="/categories/爬虫/">爬虫</a></span></div><div class="post-content"><p>在用requests爬取数据的时候，我们可能会遇到这样的问题：在浏览器中可以看到正常显示的页面数据，但是使用requests得到的结果并没有。</p>
<p>这是因为requests抓取的数据是原始的HTML文档，而我们在浏览器中看到的其实是经过JavaScript处理数据后生成的结果。</p>
<p>那么这些数据是哪儿来的呢？</p>
<p>数据的来源有多种方式：可能是通过Ajax加载的，可能是包含在HTML文档中的，也可能是经过JavaScript和特定算法计算后生成的。</p>
<p>今天主要是学习第一种方法，数据加载是一种异步加载方式，原始的页面最初不会包含某些数据，原始页面加载完后，会再向服务器请求某个接口获取数据，然后数据才被处理从而呈现到网页上，这其实就是发送了一个Ajax请求。也就是说网页的原始HTML文档不会包含任何数据，数据都是通过Ajax统一加载后再呈现出来的，这样做的好处就是在Web开发上可以做到前后端分离，而且降低服务器直接渲染页面带来的压力，所以以后这种形式的页面会越来越多。</p>
<p>那么遇到这种页面，我们怎么来爬取呢？</p>
<p>这时候就用到了Ajax分析。</p>
<h2 id="Ajax"><a href="#Ajax" class="headerlink" title="Ajax"></a>Ajax</h2><p>Ajax，全称为Asynchronous JavaScript and XML，即异步的JavaScript和XML。它不是一门编程语言，而是利用JavaScript在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。</p>
<p>对于传统的网页，如果想更新其内容，那么必须要刷新整个页面，但有了Ajax，便可以在页面不被全部刷新的情况下更新其内容。在这个过程中，页面实际上是在后台与服务器进行了数据交互，获取到数据之后，再利用JavaScript改变网页，这样网页内容就会更新了。</p>
<p>举个栗子，我们在刷头条、微博的时候，当刷到最底部的时候，再往下刷就会出现类似<strong>加载中</strong>的字样，其实这就是Ajax加载的过程。</p>
<h3 id="Ajax基本原理"><a href="#Ajax基本原理" class="headerlink" title="Ajax基本原理"></a>Ajax基本原理</h3><p>那么这个请求的过程是怎么实现的呢？其实这个从Ajax发送请求到网页更新可以简单分为３步：</p>
<blockquote>
<ol>
<li>发送请求</li>
<li>解析内容</li>
<li>渲染网页</li>
</ol>
</blockquote>
<h3 id="分析Ajax爬取今日头条街拍美图"><a href="#分析Ajax爬取今日头条街拍美图" class="headerlink" title="分析Ajax爬取今日头条街拍美图"></a>分析Ajax爬取今日头条街拍美图</h3><p>那么如何<strong>用Ajax进行分析</strong>呢？我们以爬取头条街拍图片来具体分析用Ajax分析的过程。</p>
<p>首先打开Chrome浏览器，打开头条首页：</p>
<p><img src="/2019/01/23/分析Ajax爬取今日头条街拍美图/2019-01-23-分析Ajax爬取今日头条街拍美图/首页.png" alt=""></p>
<p>然后打开 “检查” 选项，选择 Network 选项卡，刷新页面，可以看到这里出现非常多条目，但是Ajax请求有特殊的请求类型<strong>xhr</strong>，所以可以从上面的选项卡筛选出xhr类型，可以看到筛选出来的条目，即：</p>
<p><img src="/2019/01/23/分析Ajax爬取今日头条街拍美图/home/dreamgeng/Documents/Hexo/source/_posts/2019-01-23-分析Ajax爬取今日头条街拍美图/ＸＨＲ.png" alt=""></p>
<p>点击第一条，可以看到Requests Headers、URL和Response Headers的所有信息，其中可以看到：Requests Headers其中有一条为X-Requested-With:XMLHttpRequest，这就标记了此请求是Ajax请求。</p>
<p>如图：</p>
<p><img src="/2019/01/23/分析Ajax爬取今日头条街拍美图/home/dreamgeng/Documents/Hexo/source/_posts/2019-01-23-分析Ajax爬取今日头条街拍美图/Headers.png" alt=""></p>
<p>然后我们打开Priview页面，分析，然后进行<strong>数据提取</strong>，首先看到一个<code>data</code>选项卡,打开出现很多数据：</p>
<p><img src="/2019/01/23/分析Ajax爬取今日头条街拍美图/home/dreamgeng/Documents/Hexo/source/_posts/2019-01-23-分析Ajax爬取今日头条街拍美图/data.png" alt=""></p>
<p>然后打开其中一条可以看到有一个<code>image_list</code>选项，这其中其实就包含了所有图片的列表，我们只需要获取其中的url就可以把图片提取出来了：</p>
<p><img src="/2019/01/23/分析Ajax爬取今日头条街拍美图/home/dreamgeng/Documents/Hexo/source/_posts/2019-01-23-分析Ajax爬取今日头条街拍美图/image_list.png" alt=""></p>
<p><code>data</code>下还有一个<code>title</code>选项，也就是存储着图片的title。</p>
<p>然后我们就用Python来模拟这个Ajax请求，还需要分析一下URL的规律，这时再切换回Headers选项卡，可以清楚的看到这是一个GET请求，请求的URL参数有id、offset、format、keyword、autoload、count、cur_tab、rom和pd，然后下拉页面来找一下这些参数的规律。</p>
<p>这时发现只有offset在以每次20的变化，其他参数都没有变，因此就可以用offset来控制页面的分页来进行图片的提取了。</p>
<p>接下来看一下代码实战。</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>首先用<code>get_page()</code>来加载单个界面，传入offset参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(offset)</span>:</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">'offset'</span>: offset,</span><br><span class="line">        <span class="string">'format'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'keyword'</span>: <span class="string">'街拍'</span>,</span><br><span class="line">        <span class="string">'autoload'</span>: <span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'20'</span>,</span><br><span class="line">        <span class="string">'cur_tab'</span>: <span class="string">'1'</span>,</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">'https://www.toutiao.com/api/search/content/?'</span> + urlencode(params)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.json()</span><br><span class="line">    <span class="keyword">except</span> requests.ConnectionError:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>接下来用<code>get_images()</code>解析页面，获取title和图片url，并将提取出的数据生成字典:</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def get_images(json):</span><br><span class="line">    <span class="built_in">if</span> json.<span class="built_in">get</span>(<span class="string">'data'</span>):</span><br><span class="line">        <span class="built_in">for</span> item in json.<span class="built_in">get</span>(<span class="string">'data'</span>):</span><br><span class="line">            # 如果获取数据不为None,则继续执行，若不判断，则会出现TypeError: <span class="string">'NoneType'</span> object is <span class="keyword">not</span> iterable错误</span><br><span class="line">            # 只有None的类型为NoneType，且不可迭代</span><br><span class="line">            <span class="built_in">if</span> item.<span class="built_in">get</span>(<span class="string">'cell_type'</span>) is <span class="keyword">not</span> None:</span><br><span class="line">                <span class="built_in">continue</span></span><br><span class="line">            title = item.<span class="built_in">get</span>(<span class="string">'title'</span>)</span><br><span class="line">            images = item.<span class="built_in">get</span>(<span class="string">'image_list'</span>)</span><br><span class="line">            <span class="meta"># print(type(images))</span></span><br><span class="line">            <span class="built_in">for</span> <span class="built_in">image</span> in images:</span><br><span class="line">                <span class="built_in">yield</span> &#123;</span><br><span class="line">                    <span class="string">'image'</span>: <span class="built_in">image</span>.<span class="built_in">get</span>(<span class="string">'url'</span>),</span><br><span class="line">                    <span class="string">'title'</span>: title</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure>
<p>然后，提取出的图片怎么保存呢？</p>
<p>这里用<code>save_image()</code>来保存：</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"><span class="built_in">from</span> hashlib import md5</span><br><span class="line"></span><br><span class="line">def save_image(<span class="keyword">item</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>)):</span><br><span class="line">        <span class="comment"># 建立一个以 ‘title’命名的文件夹 </span></span><br><span class="line">        os.mkdir(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.<span class="built_in">get</span>(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'image'</span>))</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="comment"># 这里以ｍｄ５格式来命名文件，以去除重复</span></span><br><span class="line">            file_path = <span class="string">'&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'</span>.<span class="built_in">format</span>(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>), md5(response.content).hexdigest(),<span class="string">'jpg'</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.<span class="built_in">write</span>(response.content)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'Already Downloaded'</span>, file_path)</span><br><span class="line">    except requests.ConnectionError:</span><br><span class="line">        print(<span class="string">'Failed to Save Image'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>MD5是什么呢？</strong></p>
<p>这里用到了Python的hashlib模块，此提供了常见的摘要算法，如MD5，SHA1等等。</p>
<p>摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。这里引用廖雪峰官方网站的一个例子来理解摘要算法：</p>
<blockquote>
<p>举个例子，你写了一篇文章，内容是一个字符串<code>&#39;how to use python hashlib - by Michael&#39;</code>，并附上这篇文章的摘要是<code>&#39;2d73d4f15c0db7f5ecb321b6a65e5d6d&#39;</code>。如果有人篡改了你的文章，并发表为<code>&#39;how to use python hashlib - by Bob&#39;</code>，你可以一下子指出Bob篡改了你的文章，因为根据<code>&#39;how to use python hashlib - by Bob&#39;</code>计算出的摘要不同于原始文章的摘要。</p>
</blockquote>
<p>所以这里采用MD5来命名可以有效避免重复。</p>
<p>最后，构造一个offset数组来遍历，提取图片链接：</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">from</span> multiprocessing.pool import Pool</span><br><span class="line"></span><br><span class="line">def main(<span class="built_in">offset</span>):</span><br><span class="line">    json = get_page(<span class="built_in">offset</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">item</span> <span class="keyword">in</span> get_images(json):</span><br><span class="line">        print(<span class="keyword">item</span>)</span><br><span class="line">        save_image(<span class="keyword">item</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">GROUP_START = <span class="number">0</span>  <span class="comment"># 起始页数</span></span><br><span class="line">GROUP_END = <span class="number">10</span>  <span class="comment"># 终止页数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    groups = ([x * <span class="number">20</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(GROUP_START, GROUP_END+<span class="number">1</span>)])</span><br><span class="line">    pool.map(main, groups)</span><br><span class="line">    pool.<span class="built_in">close</span>() <span class="comment"># 关闭进程池，不再接受新的进程</span></span><br><span class="line">    pool.join()  <span class="comment"># 主进程阻塞等待子进程的退出,join方法必须在close之后使用</span></span><br></pre></td></tr></table></figure>
<p>这里利用了多进程的进程池，调用其<code>map()</code>方法实现多进程下载。</p>
<p>其中用到了<code>multiprocessing</code>模块，这是个跨平台版本的多进程模块，我们用<code>multiprocessing</code>模块的进程池Pool类，Pool类可以提供指定数量的进程供用户调用，当有新的请求提交到Pool中时，如果池还没有满，就会创建一个新的进程来执行请求。如果池满，请求就会告知先等待，直到池中有进程结束，才会创建新的进程来执行这些请求。 </p>
<p>首先定义一个pool对象，有了pool之后，我们就可以让池子对应某一个函数，我们向池子里丢数据，池子就会返回函数返回的值。</p>
<p>接下来用<code>map()</code>获取结果，在<code>map()</code>中需要放入函数和需要迭代运算的值，然后它会自动分配给CPU核。</p>
<h2 id="END"><a href="#END" class="headerlink" title="END"></a>END</h2></div><div class="tags"><a href="/tags/2019-01/">2019.01</a></div><div class="post-nav"><a class="pre" href="/2019/01/23/hello-world/">Hello World</a><a class="next" href="/2019/01/21/初识MySQL/">初识MySQL</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="http://yoursite.com"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/myblog/">myblog</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/2019-01/" style="font-size: 15px;">2019.01</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/23/hello-world/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/23/分析Ajax爬取今日头条街拍美图/">分析Ajax爬取今日头条街拍美图</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/21/初识MySQL/">初识MySQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/20/pycharm配置python解释器/">pycharm配置python解释器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/15/抓取猫眼Top100/">抓取猫眼Top100</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/廖雪峰实战day-2/">廖雪峰实战day-2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/在ubuntu上搭建HEXO博客/">在ubuntu上搭建HEXO博客</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/dreamgeng/" title="Github" target="_blank">Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">dreamgeng.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>